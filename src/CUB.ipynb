{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BaselineNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaselineNet, self).__init__()\n",
    "\n",
    "        # Convolutional layer 1\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Convolutional layer 2\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        # Convolutional layer 3\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        # Convolutional layer 4\n",
    "        self.conv4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        # Convolutional layer 5\n",
    "        self.conv5 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(128 * 14 * 14, 512)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Output layer\n",
    "        self.out = nn.Linear(512, 200)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "\n",
    "        x = x.view(-1, 128 * 14 * 14)\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from torchvision.datasets import VisionDataset\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torchvision.datasets.utils import download_file_from_google_drive\n",
    "import torchvision.transforms as transforms\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Define the transform to apply to the images\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((550, 550)),\n",
    "        transforms.RandomCrop(448, padding=8),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "class Cub2011(VisionDataset):\n",
    "    \"\"\"`CUB-200-2011 <http://www.vision.caltech.edu/visipedia/CUB-200-2011.html>`_ Dataset.\n",
    "        Args:\n",
    "            root (string): Root directory of the dataset.\n",
    "            train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "               creates from test set.\n",
    "            transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "               and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "            target_transform (callable, optional): A function/transform that takes in the\n",
    "               target and transforms it.\n",
    "            download (bool, optional): If true, downloads the dataset from the internet and\n",
    "               puts it in root directory. If dataset is already downloaded, it is not\n",
    "               downloaded again.\n",
    "    \"\"\"\n",
    "    base_folder = 'CUB_200_2011/images'\n",
    "    # url = 'http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz'\n",
    "    file_id = '1hbzc_P1FuxMkcabkgn9ZKinBwW683j45'\n",
    "    filename = 'CUB_200_2011.tgz'\n",
    "    tgz_md5 = '97eceeb196236b17998738112f37df78'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "        super(Cub2011, self).__init__(root, transform=transform, target_transform=target_transform)\n",
    "\n",
    "\n",
    "        self.train = train\n",
    "        if download:\n",
    "            self._download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted. You can use download=True to download it')\n",
    "\n",
    "    def _load_metadata(self):\n",
    "        images = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'images.txt'), sep=' ',\n",
    "                             names=['img_id', 'filepath'])\n",
    "        image_class_labels = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'image_class_labels.txt'),\n",
    "                                         sep=' ', names=['img_id', 'target'])\n",
    "        train_test_split = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'train_test_split.txt'),\n",
    "                                       sep=' ', names=['img_id', 'is_training_img'])\n",
    "\n",
    "        data = images.merge(image_class_labels, on='img_id')\n",
    "        self.data = data.merge(train_test_split, on='img_id')\n",
    "\n",
    "        class_names = pd.read_csv(os.path.join(self.root, 'CUB_200_2011', 'classes.txt'),\n",
    "                                  sep=' ', names=['class_name'], usecols=[1])\n",
    "        self.class_names = class_names['class_name'].to_list()\n",
    "        if self.train:\n",
    "            self.data = self.data[self.data.is_training_img == 1]\n",
    "        else:\n",
    "            self.data = self.data[self.data.is_training_img == 0]\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        try:\n",
    "            self._load_metadata()\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "        for index, row in self.data.iterrows():\n",
    "            filepath = os.path.join(self.root, self.base_folder, row.filepath)\n",
    "            if not os.path.isfile(filepath):\n",
    "                print(filepath)\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def _download(self):\n",
    "        import tarfile\n",
    "\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "\n",
    "        download_file_from_google_drive(self.file_id, self.root, self.filename, self.tgz_md5)\n",
    "\n",
    "        with tarfile.open(os.path.join(self.root, self.filename), \"r:gz\") as tar:\n",
    "            tar.extractall(path=self.root)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sample = self.data.iloc[idx]\n",
    "        path = os.path.join(self.root, self.base_folder, sample.filepath)\n",
    "        target = sample.target - 1  # Targets start at 1 by default, so shift to 0\n",
    "        img = Image.open(path)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return {\"image\":img, \"target\":target}\n",
    "\n",
    "\n",
    "train_dataset = Cub2011('./cub2011', train=True, download=False, transform=transform)\n",
    "test_dataset = Cub2011('./cub2011', train=False, download=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "trainloader = DataLoader(train_dataset, batch_size=200, shuffle=True, num_workers=0)\n",
    "testloader = DataLoader(test_dataset, batch_size=200, shuffle=False, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, trainloader, testloader, epochs, lr):\n",
    "    # register hooks to track activation\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # list of accuracies\n",
    "    train_accuracies, test_accuracies, train_losses, test_losses = list(), list(), list(), list()\n",
    "\n",
    "    # iterate for number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        train_outputs = []\n",
    "        y_train = []\n",
    "        # set mode to training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for data in tqdm(trainloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y = data['target']\n",
    "            images = data['image']\n",
    "            # input data\n",
    "            out = model(images)\n",
    "\n",
    "            # calculate loss\n",
    "            print(out.shape, y.shape)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            train_outputs += [out]\n",
    "            y_train += [y]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            test_outputs = []\n",
    "            y_test = []\n",
    "            test_loss = 0\n",
    "            for data in tqdm(testloader):\n",
    "                y = data['target']\n",
    "                images = data['image']\n",
    "                # input data\n",
    "                out_test = model(images)\n",
    "                test_outputs += [out_test]\n",
    "                y_test += [y]\n",
    "\n",
    "                # calculate loss\n",
    "                loss = F.cross_entropy(out_test, y)\n",
    "                test_loss += loss\n",
    "\n",
    "        train_acc = torch.Tensor(train_outputs).max(dim=-1)[1].eq(y_train).sum().item()\n",
    "        test_acc = torch.Tensor(test_outputs).max(dim=-1)[1].eq(y_test).sum().item()\n",
    "        ## add to list and print\n",
    "        train_accuracies.append(train_acc)\n",
    "        test_accuracies.append(test_acc)\n",
    "        train_losses.append(loss.item())\n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "        print('Epoch: {:03d}, Loss: {:.5f}, Train Acc: {:.5f}, Test Acc: {:.5f}'.\n",
    "              format(epoch, loss.item(), train_acc, test_acc), end=\"\\r\")\n",
    "\n",
    "model = BaselineNet()\n",
    "train(model, trainloader, testloader, 100, 0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
